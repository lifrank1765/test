{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Motion Sensor Data into Pandas DataFrame\n",
    "The following Python code imports necessary libraries and combines motion sensor data from multiple CSV files, storing it in a structured Pandas DataFrame. Subject-specific information, such as age, gender, height, and weight, is added to the dataset for comprehensive analysis.\n",
    "\n",
    "* Imports the necessary libraries, including 'os' for file operations, 'numpy' as 'np' for numerical operations, and 'pandas' as 'pd' for data handling.\n",
    "* Specifies the path to the subject data file and the directory containing motion sensor data.\n",
    "* Defines two functions:\n",
    "    'get_all_dataset_paths' that recursively walks through the specified directory and collects paths to all CSV files.\n",
    "    'load_whole_dataframe_from_paths' that reads and combines motion sensor data from these paths into a single Pandas DataFrame. It also enriches the data with subject information from the subject data file.\n",
    "* Loads the subject data from the CSV file 'data_subjects_info.csv' into a Pandas DataFrame.\n",
    "* Calls 'get_all_dataset_paths' to obtain a list of paths to all CSV files in the specified directory.\n",
    "* Calls 'load_whole_dataframe_from_paths' to create a comprehensive DataFrame containing motion sensor data, with additional subject information.\n",
    "\n",
    "This code is a critical step in preparing motion sensor data for analysis and is commonly used in data science and machine learning projects involving motion data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# change these following three lines only\n",
    "subject_data_file = 'data_subjects_info.csv'\n",
    "data_dir = 'E:/motion-sense-master/data/A_DeviceMotion_data'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "os.chdir(os.pardir)\n",
    "\n",
    "def get_all_dataset_paths(input_dir) -> []:\n",
    "    input_files = []\n",
    "    for dirs, subdirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                input_files.append(os.path.join(dirs, file))\n",
    "    return input_files\n",
    "\n",
    "def load_whole_dataframe_from_paths(paths, meta) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for p in paths:\n",
    "        p = p.replace(\"\\\\\",'/')\n",
    "        c_dir, c_file = p.split('/')[-2], p.split('/')[-1]\n",
    "        \n",
    "        c_cat, c_ses = c_dir.split('_')[-2], c_dir.split('_')[-1]\n",
    "        c_sub = c_file.split('_')[-1].split('.')[-2]\n",
    "        \n",
    "        tdf = pd.read_csv(p, encoding = \"utf-8\")\n",
    "        tdf = tdf.assign(subject_id = int(c_sub))\n",
    "        tdf = tdf.assign(session_id = int(c_ses))\n",
    "        tdf = tdf.assign(category = str(c_cat))\n",
    "        tdf = tdf.assign(age = int(meta.age[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(gender = int(meta.gender[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(height = int(meta.height[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(weight = int(meta.weight[int(c_sub) - 1]))\n",
    "\n",
    "        df = pd.concat([df, tdf])\n",
    "        print(p,c_cat,c_sub)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "subject_data_frame = pd.DataFrame(pd.read_csv(subject_data_file, encoding = \"utf-8\"))\n",
    "all_dataset_paths = get_all_dataset_paths(data_dir)\n",
    "data_frame = load_whole_dataframe_from_paths(all_dataset_paths, subject_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full DataFrame at a glance\n",
    "The whole raw DataFrame looks like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Removing Unnecessary Columns\n",
    "In this Python code, a copy of the original DataFrame 'data_frame' is created. Subsequently, several columns ('Unnamed: 0', 'subject_id', 'session_id', 'age', 'gender', 'height', and 'weight') are removed from the copied DataFrame 'df' to streamline the dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_frame.copy() #making a copy of original dataframe\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.drop('subject_id', axis=1, inplace=True)\n",
    "df.drop('session_id', axis=1, inplace=True)\n",
    "df.drop('age', axis=1, inplace=True)\n",
    "df.drop('gender', axis=1, inplace=True)\n",
    "df.drop('height', axis=1, inplace=True)\n",
    "df.drop('weight', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data for Machine Learning\n",
    "Following Python code snippet utilizes the 'LabelEncoder' from the scikit-learn library to transform the 'category' column in the DataFrame 'df' into numerical codes. These codes are stored in a new 'code' column, and the original 'category' column is subsequently removed from the DataFrame, preparing the data for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lEncoder = LabelEncoder()\n",
    "labels = lEncoder.fit(df.category)\n",
    "df['code'] = lEncoder.transform(df.category)\n",
    "df.drop('category', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Categorical Data Distribution\n",
    "We use Seaborn and Matplotlib to create a countplot, visualizing the distribution of numerical codes in the 'code' column of the DataFrame 'df.' This plot provides insight into the frequency of different categories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "sns.countplot(df, x='code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data for Machine Learning\n",
    "The following code uses the 'train_test_split' function from scikit-learn to divide the dataset into training and testing sets. It separates the input features ('x_columns') and the target variable ('y_columns') with a 20% test set size, ensuring that the lengths of the training sets for both features and labels are the same, as asserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_columns = df.iloc[:, 0:12]\n",
    "y_columns = df.iloc[:, 12:13]\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(x_columns, y_columns, test_size=0.2, shuffle=False)\n",
    "assert(len(trainx) == len(trainy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing Data for Temporal Analysis\n",
    "We define a sequence generator function that creates sequences of input features and corresponding target labels from the training and testing data. These sequences have a window length of 150 with a stride of 10. The mode of target labels within each sequence is calculated to represent the label for that sequence. This prepares the data for temporal analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "WINDOW_LENGTH = 150\n",
    "STRIDE_LENGTH = 10\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 12\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS_SIZE = 10\n",
    "\n",
    "def sequence_generator(x, y, length, stride):\n",
    "    seq_x = []\n",
    "    seq_y = []\n",
    "    data_length = len(x)\n",
    "\n",
    "    for i in range(0, data_length - length + 1, stride):\n",
    "        input_sequence = x.iloc[i : i + length]\n",
    "        target_sequence = y.iloc[i : i + length]\n",
    "        target_mode = mode(target_sequence.values)[0][0]\n",
    "        seq_x.append(input_sequence)\n",
    "        seq_y.append(target_mode)\n",
    "    return np.array(seq_x), np.array(seq_y)\n",
    "\n",
    "tx, ty = sequence_generator(trainx, trainy, WINDOW_LENGTH, STRIDE_LENGTH)\n",
    "vx, vy = sequence_generator(testx, testy, WINDOW_LENGTH, STRIDE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsai.basics import *\n",
    "\n",
    "X, y, splits = get_classification_data('LSST', split_data=False)\n",
    "print(y.shape,X.shape,y[0])\n",
    "X = np.concatenate([tx,vx])\n",
    "y = np.concatenate([ty,vy])\n",
    "\n",
    "splits = [ [i for i in range(ty.shape[0]) ],[ i for i in range(ty.shape[0],y.shape[0])] ]\n",
    "\n",
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "mv_clf = TSClassifier(X, y, splits=splits, path='models', arch=\"InceptionTimePlus\", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())\n",
    "mv_clf.fit_one_cycle(10, 1e-2)\n",
    "mv_clf.export(\"mv_clf.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSAI other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.models.MINIROCKET import *\n",
    "model = MiniRocketClassifier()\n",
    "timer.start(False)\n",
    "model.fit(xt, yt)\n",
    "t = timer.stop()\n",
    "print(f'valid accuracy    : {model.score(xv, yv):.3%} time: {t}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
